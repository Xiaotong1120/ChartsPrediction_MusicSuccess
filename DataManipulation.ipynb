{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69f79024-9125-469e-ae59-9610455661fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, desc, avg, corr\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, BooleanType, DateType, StructType, StructField\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59b7ae62-b1dc-4a4c-b80e-494e009e1ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/05 18:51:19 INFO SparkEnv: Registering MapOutputTracker\n",
      "25/04/05 18:51:19 INFO SparkEnv: Registering BlockManagerMaster\n",
      "25/04/05 18:51:19 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "25/04/05 18:51:19 INFO SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    }
   ],
   "source": [
    "# Initialize SparkSession with memory optimization\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spotify Data Cleaning\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"2g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "414a4ac0-22ed-4da9-8187-a2f646773b11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Schema:\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- rank: integer (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- artist: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- chart: string (nullable = true)\n",
      " |-- trend: string (nullable = true)\n",
      " |-- streams: double (nullable = true)\n",
      " |-- track_id: string (nullable = true)\n",
      " |-- album: string (nullable = true)\n",
      " |-- popularity: double (nullable = true)\n",
      " |-- duration_ms: double (nullable = true)\n",
      " |-- explicit: boolean (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- available_markets: string (nullable = true)\n",
      " |-- af_danceability: double (nullable = true)\n",
      " |-- af_energy: double (nullable = true)\n",
      " |-- af_key: double (nullable = true)\n",
      " |-- af_loudness: double (nullable = true)\n",
      " |-- af_mode: double (nullable = true)\n",
      " |-- af_speechiness: double (nullable = true)\n",
      " |-- af_acousticness: double (nullable = true)\n",
      " |-- af_instrumentalness: double (nullable = true)\n",
      " |-- af_liveness: double (nullable = true)\n",
      " |-- af_valence: double (nullable = true)\n",
      " |-- af_tempo: double (nullable = true)\n",
      " |-- af_time_signature: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data from GCP DataProc\n",
    "file_path = \"gs://dataproc-staging-us-central1-361128386781-eo9ksqfa/merged_data.csv\"\n",
    "\n",
    "# Define explicit schema\n",
    "schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),  # String ID like \"0\", \"1\", etc.\n",
    "    StructField(\"title\", StringType(), True),  # Track title\n",
    "    StructField(\"rank\", IntegerType(), True),  # Numeric rank on chart\n",
    "    StructField(\"date\", DateType(), True),  # Date format like \"2017-01-01\"\n",
    "    StructField(\"artist\", StringType(), True),  # Artist name(s)\n",
    "    StructField(\"url\", StringType(), True),  # Spotify URL\n",
    "    StructField(\"region\", StringType(), True),  # Region like \"Argentina\"\n",
    "    StructField(\"chart\", StringType(), True),  # Chart type like \"top200\"\n",
    "    StructField(\"trend\", StringType(), True),  # Trend like \"SAME_POSITION\", \"MOVE_UP\"\n",
    "    StructField(\"streams\", DoubleType(), True),  # Number of streams (appears as float in sample)\n",
    "    StructField(\"track_id\", StringType(), True),  # Unique track identifier\n",
    "    StructField(\"album\", StringType(), True),  # Album title\n",
    "    StructField(\"popularity\", DoubleType(), True),  # Popularity score (float in sample)\n",
    "    StructField(\"duration_ms\", DoubleType(), True),  # Duration in ms (float in sample)\n",
    "    StructField(\"explicit\", BooleanType(), True),  # Boolean as \"True\" or \"False\" strings\n",
    "    StructField(\"release_date\", StringType(), True),  # Release date as string\n",
    "    StructField(\"available_markets\", StringType(), True),  # String representing array of markets\n",
    "    StructField(\"af_danceability\", DoubleType(), True),  # Audio feature: danceability\n",
    "    StructField(\"af_energy\", DoubleType(), True),  # Audio feature: energy\n",
    "    StructField(\"af_key\", DoubleType(), True),  # Audio feature: key\n",
    "    StructField(\"af_loudness\", DoubleType(), True),  # Audio feature: loudness\n",
    "    StructField(\"af_mode\", DoubleType(), True),  # Audio feature: mode\n",
    "    StructField(\"af_speechiness\", DoubleType(), True),  # Audio feature: speechiness\n",
    "    StructField(\"af_acousticness\", DoubleType(), True),  # Audio feature: acousticness\n",
    "    StructField(\"af_instrumentalness\", DoubleType(), True),  # Audio feature: instrumentalness\n",
    "    StructField(\"af_liveness\", DoubleType(), True),  # Audio feature: liveness\n",
    "    StructField(\"af_valence\", DoubleType(), True),  # Audio feature: valence\n",
    "    StructField(\"af_tempo\", DoubleType(), True),  # Audio feature: tempo\n",
    "    StructField(\"af_time_signature\", DoubleType(), True)  # Audio feature: time signature\n",
    "])\n",
    "\n",
    "# Load the data with explicit schema instead of inferring\n",
    "spotify_df = spark.read.csv(file_path, header=True, schema=schema)\n",
    "\n",
    "# Print data schema\n",
    "print(\"Data Schema:\")\n",
    "spotify_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab5baa09-c4cf-4ce8-86e8-fa525ea0838a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tracks: 200290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count number of unique songs by track_id\n",
    "unique_tracks = spotify_df.select(\"track_id\").distinct().count()\n",
    "print(f\"Number of unique tracks: {unique_tracks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "274a7384-3447-472c-8906-90fa2e7b57c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns after dropping specified ones:\n",
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- artist: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- track_id: string (nullable = true)\n",
      " |-- album: string (nullable = true)\n",
      " |-- popularity: double (nullable = true)\n",
      " |-- duration_ms: double (nullable = true)\n",
      " |-- explicit: boolean (nullable = true)\n",
      " |-- af_danceability: double (nullable = true)\n",
      " |-- af_energy: double (nullable = true)\n",
      " |-- af_key: double (nullable = true)\n",
      " |-- af_loudness: double (nullable = true)\n",
      " |-- af_mode: double (nullable = true)\n",
      " |-- af_speechiness: double (nullable = true)\n",
      " |-- af_acousticness: double (nullable = true)\n",
      " |-- af_instrumentalness: double (nullable = true)\n",
      " |-- af_liveness: double (nullable = true)\n",
      " |-- af_valence: double (nullable = true)\n",
      " |-- af_tempo: double (nullable = true)\n",
      " |-- af_time_signature: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop specified columns\n",
    "columns_to_drop = [\"id\", \"rank\", \"date\", \"url\", \"chart\", \"trend\", \"streams\", \"release_date\", \"available_markets\"]\n",
    "spotify_df_reduced = spotify_df.drop(*columns_to_drop)\n",
    "\n",
    "# Show remaining columns\n",
    "print(\"Remaining columns after dropping specified ones:\")\n",
    "spotify_df_reduced.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f0a7f62-b2c2-4814-a511-46387323d7d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count before deduplication: 26174269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count after deduplication: 200290\n",
      "Removed 25973979 duplicate rows (99.23% of data)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count rows before deduplication\n",
    "before_dedup = spotify_df_reduced.count()\n",
    "print(f\"Row count before deduplication: {before_dedup}\")\n",
    "\n",
    "# Deduplicate based on track_id\n",
    "spotify_df_deduplicated = spotify_df_reduced.dropDuplicates([\"track_id\"])\n",
    "\n",
    "# Count rows after deduplication\n",
    "after_dedup = spotify_df_deduplicated.count()\n",
    "print(f\"Row count after deduplication: {after_dedup}\")\n",
    "print(f\"Removed {before_dedup - after_dedup} duplicate rows ({(before_dedup - after_dedup) / before_dedup * 100:.2f}% of data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97caabcc-5a31-4fce-a086-41b80e180329",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving deduplicated data to: gs://dataproc-staging-us-central1-361128386781-eo9ksqfa/spotify_deduplicated_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/05 19:01:13 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Save the deduplicated data to CSV\n",
    "output_path = \"gs://dataproc-staging-us-central1-361128386781-eo9ksqfa/spotify_deduplicated_data.csv\"\n",
    "print(f\"Saving deduplicated data to: {output_path}\")\n",
    "spotify_df_deduplicated.write.mode(\"overwrite\").option(\"header\", \"true\").csv(output_path)\n",
    "print(\"Data saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
